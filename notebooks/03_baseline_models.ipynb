{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03_baseline_models.ipynb\n",
    "\n",
    "**Objetivo:**  \n",
    "Entrenar y evaluar modelos baseline (Árbol de Decisión y Regresión Logística) para predecir el éxito de startups a partir de sus características procesadas.\n",
    "\n",
    "**Contenido:**  \n",
    "- Limpieza y preparación de datos finales.\n",
    "- Entrenamiento de modelos baseline.\n",
    "- Evaluación con métricas clásicas y visualización de resultados.\n",
    "- Guardado de modelos para comparativas posteriores.\n",
    "\n",
    "**Dataset:**  \n",
    "Se utiliza el dataset procesado (`startup_data_processed.csv`) generado en la fase de feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RANDOM_STATE, TEST_SIZE, TARGET_COLUMN, MODELS_DIR, PROCESSED_DATA_DIR\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Cargar datos procesados\u001b[39;00m\n\u001b[32m     16\u001b[39m df = pd.read_csv(PROCESSED_DATA_DIR / \u001b[33m\"\u001b[39m\u001b[33mstartup_data_processed.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "from src.config import RANDOM_STATE, TEST_SIZE, TARGET_COLUMN, MODELS_DIR, PROCESSED_DATA_DIR\n",
    "\n",
    "\n",
    "# Cargar datos procesados\n",
    "df = pd.read_csv(PROCESSED_DATA_DIR / \"startup_data_processed.csv\")\n",
    "display(df.head())\n",
    "print(f\"Shape inicial: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# Añadir directorio raíz al path\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "\n",
    "from src.config import PROCESSED_DATA_DIR, MODELS_DIR, RANDOM_STATE, TEST_SIZE, TARGET_COLUMN\n",
    "\n",
    "# Cargar datos procesados\n",
    "df = pd.read_csv(PROCESSED_DATA_DIR / \"startup_data_processed.csv\")\n",
    "\n",
    "# Eliminar columnas irrelevantes y dummies problemáticas (identificadores, fechas, nombres, ciudades, etc.)\n",
    "prefijos_a_eliminar = [\n",
    "    'closed', 'name', 'city', 'id', 'object', 'last', 'first', 'zip', 'Unnamed:', 'founded'\n",
    "]\n",
    "# Elimina cualquier columna que comience por alguno de estos prefijos\n",
    "cols_problematicas = [col for col in df.columns if any(col.startswith(pref) for pref in prefijos_a_eliminar)]\n",
    "df = df.drop(columns=cols_problematicas)\n",
    "\n",
    "# Eliminar columnas irrelevantes restantes por nombre exacto\n",
    "columnas_a_eliminar = [\n",
    "    'Unnamed: 0', 'id', 'object_id', 'Unnamed: 6', 'state_code.1',\n",
    "    'zip_code', 'city', 'name', 'closed_at',\n",
    "    'founded_at', 'first_funding_at', 'last_funding_at', 'labels'\n",
    "]\n",
    "df = df.drop(columns=[col for col in columnas_a_eliminar if col in df.columns])\n",
    "\n",
    "# Eliminar columnas con baja varianza (opcional, pero recomendable)\n",
    "cols_baja_var = [col for col in df.columns if df[col].nunique() <= 1]\n",
    "df = df.drop(columns=cols_baja_var)\n",
    "\n",
    "# Separar features y target\n",
    "X = df.drop(TARGET_COLUMN, axis=1)\n",
    "y = df[TARGET_COLUMN]\n",
    "\n",
    "# Dividir en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base: Árbol de Decisión\n",
    "print(\"\\n--- Entrenando Árbol de Decisión ---\")\n",
    "dt_classifier = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluación en train y test\n",
    "dt_train_pred = dt_classifier.predict(X_train)\n",
    "dt_test_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy en train: {accuracy_score(y_train, dt_train_pred):.4f}\")\n",
    "print(f\"Accuracy en test: {accuracy_score(y_test, dt_test_pred):.4f}\")\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(y_test, dt_test_pred))\n",
    "\n",
    "# Matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, dt_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Valor real')\n",
    "plt.title('Matriz de Confusión - Árbol de Decisión')\n",
    "plt.savefig('../reports/figures/model_performance/dt_confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo baseline: Regresión Logística\n",
    "print(\"\\n--- Entrenando Regresión Logística ---\")\n",
    "lr_classifier = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluación en train y test\n",
    "lr_train_pred = lr_classifier.predict(X_train)\n",
    "lr_test_pred = lr_classifier.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy en train: {accuracy_score(y_train, lr_train_pred):.4f}\")\n",
    "print(f\"Accuracy en test: {accuracy_score(y_test, lr_test_pred):.4f}\")\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(y_test, lr_test_pred))\n",
    "\n",
    "# Matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, lr_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Valor real')\n",
    "plt.title('Matriz de Confusión - Regresión Logística')\n",
    "plt.savefig('../reports/figures/model_performance/lr_confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparativa de modelos baseline\n",
    "models = ['Árbol de Decisión', 'Regresión Logística']\n",
    "train_scores = [\n",
    "    accuracy_score(y_train, dt_train_pred),\n",
    "    accuracy_score(y_train, lr_train_pred)\n",
    "]\n",
    "test_scores = [\n",
    "    accuracy_score(y_test, dt_test_pred),\n",
    "    accuracy_score(y_test, lr_test_pred)\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, train_scores, width, label='Train')\n",
    "plt.bar(x + width/2, test_scores, width, label='Test')\n",
    "\n",
    "plt.xlabel('Modelos')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparativa de Modelos Baseline')\n",
    "plt.xticks(x, models)\n",
    "plt.legend()\n",
    "plt.ylim(0.5, 1.0)\n",
    "plt.savefig('../reports/figures/model_performance/baseline_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelos baseline\n",
    "import os\n",
    "os.makedirs(MODELS_DIR / \"baseline\", exist_ok=True)\n",
    "\n",
    "with open(MODELS_DIR / \"baseline\" / \"decision_tree.pkl\", 'wb') as f:\n",
    "    pickle.dump(dt_classifier, f)\n",
    "\n",
    "with open(MODELS_DIR / \"baseline\" / \"logistic_regression.pkl\", 'wb') as f:\n",
    "    pickle.dump(lr_classifier, f)\n",
    "\n",
    "print(\"Modelos baseline guardados exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "En este análisis se han evaluado dos modelos baseline: un Árbol de Decisión sin restricciones y una Regresión Logística. El Árbol de Decisión alcanza una precisión perfecta sobre el conjunto de entrenamiento (accuracy = 1.00), lo que evidencia un claro sobreajuste y una baja capacidad de generalización. Por otro lado, la Regresión Logística muestra un mejor equilibrio entre el rendimiento en entrenamiento y prueba, logrando una mayor capacidad de generalización sobre datos no vistos.\n",
    "\n",
    "Estos resultados demuestran la importancia de regularizar los modelos y utilizar enfoques más robustos para evitar el sobreajuste. Los modelos baseline sirven como referencia fundamental para comparar y justificar mejoras en futuras etapas del proyecto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
