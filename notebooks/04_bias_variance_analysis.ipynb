{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Sesgo-Varianza en Modelos de Startups\n",
    "\n",
    "Este notebook realiza un diagnóstico del equilibrio entre sesgo y varianza en nuestros modelos para predecir el éxito de startups. Analizaremos por qué nuestros modelos base están mostrando un rendimiento perfecto (100% de precisión) y determinaremos si esto se debe a sobreajuste, fuga de datos u otros problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Añadir directorio raíz al path\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "\n",
    "from src.config import PROCESSED_DATA_DIR, MODELS_DIR, RANDOM_STATE, TEST_SIZE, TARGET_COLUMN\n",
    "from src.models.bias_variance import plot_learning_curve, plot_validation_curve, diagnose_bias_variance, plot_complexity_analysis\n",
    "\n",
    "# Configuración para visualizaciones\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "\n",
    "Primero cargamos los datos procesados y realizamos la división en conjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cargar datos procesados\n",
    "df = pd.read_csv(PROCESSED_DATA_DIR / \"startup_data_processed.csv\")\n",
    "\n",
    "# Separar features y target\n",
    "X = df.drop(TARGET_COLUMN, axis=1)\n",
    "y = df[TARGET_COLUMN]\n",
    "\n",
    "# División en train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y)\n",
    "\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {X_test.shape}\")\n",
    "print(f\"Distribución de clases en entrenamiento:\\n{y_train.value_counts()}\")\n",
    "print(f\"Distribución de clases en prueba:\\n{y_test.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo base (Árbol de Decisión)\n",
    "\n",
    "Entrenamos un árbol de decisión sin restricciones para analizar su comportamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Entrenar árbol de decisión sin restricciones\n",
    "dt_classifier = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluación básica\n",
    "y_train_pred = dt_classifier.predict(X_train)\n",
    "y_test_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy en train: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"Accuracy en test: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnóstico de Sesgo-Varianza\n",
    "\n",
    "Utilizamos las funciones de diagnóstico para analizar el equilibrio entre sesgo y varianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Diagnóstico completo\n",
    "diagnosis = diagnose_bias_variance(dt_classifier, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"Diagnóstico de sesgo-varianza:\")\n",
    "for key, value in diagnosis.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva de Aprendizaje\n",
    "\n",
    "La curva de aprendizaje nos muestra cómo cambia el rendimiento del modelo a medida que aumenta el tamaño del conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Curva de aprendizaje\n",
    "plt = plot_learning_curve(\n",
    "    DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    X, y, cv=5, n_jobs=-1\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Complejidad del Modelo\n",
    "\n",
    "Analizamos cómo afecta la complejidad del modelo (profundidad del árbol) al rendimiento en entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Análisis de complejidad: profundidad máxima del árbol\n",
    "max_depths = [1, 2, 3, 5, 7, 10, 15, 20, 30, None]\n",
    "plt = plot_complexity_analysis(\n",
    "    DecisionTreeClassifier,\n",
    "    'max_depth',\n",
    "    max_depths,\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva de Validación para otros Parámetros\n",
    "\n",
    "Analizamos el efecto de otros parámetros de regularización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Curva de validación para min_samples_leaf\n",
    "min_samples_leaf_range = [1, 2, 5, 10, 20, 50, 100]\n",
    "plt = plot_validation_curve(\n",
    "    DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    X, y,\n",
    "    \"min_samples_leaf\",\n",
    "    min_samples_leaf_range,\n",
    "    cv=5, n_jobs=-1\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación Cruzada\n",
    "\n",
    "Utilizamos validación cruzada para obtener una estimación más robusta del rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Validación cruzada con diferentes configuraciones\n",
    "cv_results = {}\n",
    "\n",
    "# Árbol sin restricciones\n",
    "dt = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "scores = cross_val_score(dt, X, y, cv=5, scoring='accuracy')\n",
    "cv_results['Sin restricciones'] = scores\n",
    "\n",
    "# Árbol con max_depth=3\n",
    "dt_shallow = DecisionTreeClassifier(max_depth=3, random_state=RANDOM_STATE)\n",
    "scores = cross_val_score(dt_shallow, X, y, cv=5, scoring='accuracy')\n",
    "cv_results['max_depth=3'] = scores\n",
    "\n",
    "# Árbol con min_samples_leaf=20\n",
    "dt_pruned = DecisionTreeClassifier(min_samples_leaf=20, random_state=RANDOM_STATE)\n",
    "scores = cross_val_score(dt_pruned, X, y, cv=5, scoring='accuracy')\n",
    "cv_results['min_samples_leaf=20'] = scores\n",
    "\n",
    "# Visualizar resultados\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=cv_df)\n",
    "plt.title('Comparación de Configuraciones con Validación Cruzada')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Mostrar medias y desviaciones estándar\n",
    "print(\"Medias y desviaciones estándar:\")\n",
    "for config, scores in cv_results.items():\n",
    "    print(f\"{config}: {scores.mean():.4f} ± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Características Importantes\n",
    "\n",
    "Examinamos qué características son más importantes para el modelo, lo que puede ayudar a identificar posibles fugas de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Obtener importancia de características\n",
    "feature_importances = dt_classifier.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Crear DataFrame para visualización\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importances\n",
    "})\n",
    "\n",
    "# Ordenar por importancia\n",
    "importance_df = importance_df.sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Mostrar las 20 características más importantes\n",
    "top_20 = importance_df.head(20)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='importance', y='feature', data=top_20)\n",
    "plt.title('Top 20 Características más Importantes')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Imprimir las 10 más importantes\n",
    "print(\"Las 10 características más importantes:\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "Basado en los análisis anteriores, podemos sacar las siguientes conclusiones:\n",
    "\n",
    "1. **Diagnóstico de sobreajuste**: El árbol de decisión sin restricciones muestra signos claros de sobreajuste, con un rendimiento perfecto tanto en entrenamiento como en prueba.\n",
    "\n",
    "2. **Posibles causas**:\n",
    "   - Sobreajuste extremo debido a la alta dimensionalidad de los datos (muchas características)\n",
    "   - Posible fuga de datos donde alguna variable está directamente relacionada con el objetivo\n",
    "   - Conjunto de datos demasiado pequeño o no representativo\n",
    "\n",
    "3. **Recomendaciones**:\n",
    "   - Revisar las características más importantes para identificar posibles fugas de datos\n",
    "   - Aplicar técnicas de regularización (limitar profundidad, aumentar muestras mínimas por hoja)\n",
    "   - Utilizar validación cruzada para evaluaciones más robustas\n",
    "   - Probar con diferentes semillas aleatorias para verificar la estabilidad de los resultados\n",
    "   - Considerar técnicas de reducción de dimensionalidad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
